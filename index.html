<!DOCTYPE html>
<html lang="en">
<head>
  <link href="https://fonts.googleapis.com/css2?family=Playfair+Display:wght@700&display=swap" rel="stylesheet">
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Jarod Lévy | AI × Neuroscience</title>

  <meta name="description" content="Jarod Lévy — PhD student in AI & Neuroscience at Meta FAIR Paris and Inria MIND. Brain decoding, neural communication, non-invasive interfaces." />
  <meta name="author" content="Jarod Lévy" />
  <link rel="canonical" href="https://jarodlevy.com" />
  <link rel="stylesheet" href="style.css" />
  <!-- Iconify web component (prebuilt icons, no download needed) -->
  <script src="https://cdn.jsdelivr.net/npm/iconify-icon@2.1.0/dist/iconify-icon.min.js" defer></script>
</head>

<body>
  <header class="site-nav">
    <div class="nav-inner">
      <a href="#intro" class="brand">Jarod Lévy</a>
      <nav>
        <a href="#lead">Publications</a>
        <a href="#weekly">Writing</a>
        <a href="#cv">CV</a>
        <a href="#outside-work">Outside Work</a>
      </nav>
    </div>
  </header>

  <!-- INTRO -->
  <section id="intro">
    <div class="intro-grid">
      <div class="intro-left">
        <img src="jarod.jpeg" alt="Jarod Lévy portrait" class="intro-photo" />
        <h1>Jarod Lévy</h1>
        <p class="mono role">PhD Student — AI × Neuroscience</p>
        <p class="mono small">MIND @ Inria × Brain&AI @ Meta FAIR Paris</p>
        <p class="mono small">Decoding communication through non-invasive brain recordings.</p>
        <p class="mono small subtle">Paris, France • <a href="mailto:jarod@meta.com">jarod@meta.com</a></p>
        <div class="intro-logos">
          <img src="meta.png" alt="Meta logo" class="intro-logo" />
          <img src="inria.png" alt="Inria logo" class="intro-logo" />
        </div>
      </div>

      <div class="intro-right">
        <p>
          Hi! My name is Jarod. I’m a PhD student at INRIA and Meta in Paris. I am supervised by 
          <a href="https://sdascoli.github.io/" target="_blank" rel="noopener noreferrer">Stéphane d’Ascoli</a>
          and 
          <a href="https://tommoral.github.io/about.html" target="_blank" rel="noopener noreferrer">Thomas Moreau</a>. 
          I work with the Brain&AI team led by 
          <a href="https://kingjr.github.io/" target="_blank" rel="noopener noreferrer">Jean-Rémi King</a>.
        </p>
        <p>
          My research is centered on  <strong>building AI models to better understand and decode the brain</strong> through non-invasive recordings.
          Before this, I was a research intern at Meta, Institut Pasteur and New York Genome Center.
        </p>
        <div class="socials intro-socials">
          <a href="https://scholar.google.com/citations?user=jx5DNj0AAAAJ&hl=fr&oi=sra" title="Google Scholar" aria-label="Google Scholar">
            <iconify-icon icon="simple-icons:googlescholar"></iconify-icon>
          </a>
          <a href="https://github.com/jarod1212" title="GitHub" aria-label="GitHub">
            <iconify-icon icon="mdi:github"></iconify-icon>
          </a>
          <a href="https://x.com/JarodLevy" title="X (Twitter)" aria-label="X (Twitter)">
            <iconify-icon icon="simple-icons:x"></iconify-icon>
          </a>
          <a href="https://www.linkedin.com/in/jarod-l%C3%A9vy-645b4214b/" title="LinkedIn" aria-label="LinkedIn">
            <iconify-icon icon="mdi:linkedin"></iconify-icon>
          </a>
        </div>
      </div>
    </div>

    <!-- PHD TIMER -->
    <div class="countdown">
      <h3>Remaining time until the end of my PhD</h3>
      <div class="time-grid mono" id="time-grid">
        <div><span id="yy">0</span><label>years</label></div>
        <div><span id="mm">0</span><label>months</label></div>
      </div>
      <div class="bar-bg"><div id="progress-bar"></div></div>
      <p id="countdown" class="subtle mono tiny"></p>
    </div>
  </section>

  <!-- LEAD PUBLICATIONS -->
  <section id="lead" class="reveal">
    <div class="section-head"><h2>Publications</h2></div>

    <h3 class="section-subhead">Lead Publications</h3>

    <article class="pub-row">
      <div class="pub-rail"><span class="chip chip-primary">Under Review • 2025</span></div>
      <div class="pub-illustration">
        <video src="decoded_sentences.mov" autoplay loop muted playsinline style="width: 100%; height: auto; border-radius: 12px; border: 1px solid var(--line); margin-bottom: 18px; clip-path: inset(0 0 0 1%);"></video>
        <video src="animated_b2q_paper.mp4" autoplay loop muted playsinline style="width: 100%; height: auto; border-radius: 12px; border: 1px solid var(--line);"></video>
      </div>
      <div class="pub-body">
        <h3>Brain-to-text decoding: A non-invasive approach via typing</h3>
        <p class="authors">J. Lévy, M. Zhang, S. Pinet, J. Rapin, H. Banville, S. d’Ascoli, J.-R. King</p>
        <p class="summary">
          We present <strong>Brain2Qwerty</strong>, a deep learning model that decodes full sentences from non-invasive brain recordings (EEG and MEG) as participants type memorized sentences. In a cohort of 35 volunteers, <strong>Brain2Qwerty</strong> achieved an average character error rate of 32% with MEG and 67% with EEG, reaching 19% for the best individuals and generalizing to unseen sentences. Analyses reveal contributions from both motor and higher cognitive processes. These results bring non-invasive brain decoding closer to invasive neuroprostheses, paving the way for safe communication interfaces for patients unable to speak or move.
        </p>
        <div class="links">
          <a class="ghost" href="https://arxiv.org/abs/2502.17480" target="_blank">Paper (PDF)</a>
          <a class="ghost" href="Brain2Qwerty.pptx" download>Slides</a>
          <a class="ghost" href="https://ai.meta.com/research/publications/brain-to-text-decoding-a-non-invasive-approach-via-typing/" target="_blank">Meta Blog Post</a>
          <a class="ghost" href="https://medium.com/predict/metas-ai-can-now-read-your-mind-yes-really-117916343757" target="_blank">Medium</a>
          
          <div class="links-subhead">They talk about our paper:</div>
          <a class="ghost" href="https://www.bbc.com/audio/play/w3ct5wnj" target="_blank">BBC</a>
          <a class="ghost" href="https://www.forbes.com/sites/luisromero/2025/02/19/metas-mind-reader-brain2qwerty-translates-thoughts-into-text/" target="_blank">Forbes</a>
          <a class="ghost" href="https://www.technologyreview.com/2025/02/07/1111292/meta-has-an-ai-for-brain-typing-but-its-stuck-in-the-lab/" target="_blank">MIT Technology Review</a>
          <a class="ghost" href="https://www.france.tv/documentaires/documentaires-societe/l-homme-a-la-machine/" target="_blank">France 2</a>
          <a class="ghost" href="https://www.radiofrance.fr/franceinfo/podcasts/aujourd-hui-c-est-demain/meta-met-au-point-une-technique-permettant-d-ecrire-une-phrase-par-la-pensee-sans-avoir-recours-a-un-implant-cerebral-4382951" target="_blank">France Info</a>
          <a class="ghost" href="https://www.deeplearning.ai/the-batch/tag/feb-26-2025/" target="_blank">Andrew Ng’s The Batch</a>
          <a class="ghost" href="https://www.marktechpost.com/2025/02/09/meta-ai-introduces-brain2qwerty-a-new-deep-learning-model-for-decoding-sentences-from-brain-activity-with-eeg-or-meg-while-participants-typed-briefly-memorized-sentences-on-a-qwerty-keyboard/" target="_blank">MarkTechPost</a>
          <a class="ghost" href="https://themunicheye.com/meta-achieves-80-accuracy-decoding-brain-activity-9981" target="_blank">The Munich Eye</a>
        </div>
      </div>
    </article>

    <article class="pub-row">
      <div class="pub-rail"><span class="chip">GRETSI • 2025</span></div>
      <div class="pub-illustration">
        <img src="table_gretsi.png" alt="GRETSI main figure" class="gretsi-img">
        <img src="main_figure_GRETSI.png" alt="GRETSI figure 2" class="gretsi-img" style="margin-top: 18px;">
      </div>
      <div class="pub-body">
        <h3>Deep Learning on M/EEG signals: Adapt your model, not your preprocessing</h3>
        <p class="authors">J. Lévy, H. J. Banville, J.-R. King, S. Pinet, J. Rapin, S. d’Ascoli, T. Moreau</p>
        <p class="summary">
          This study investigates the impact of preprocessing EEG (electroencephalography) and MEG (magnetoencephalography) signals on the performance of deep learning models. Our results show that minimal preprocessing significantly reduces computational cost while maintaining performance comparable to more complex approaches, across datasets and models. Our observations suggest that model choice has a more decisive influence on the outcome than the complexity of the applied preprocessing.
        </p>
        <div class="links">
          <a class="ghost" href="https://gretsi.fr/data/colloque/pdf/2025_levy1559.pdf" target="_blank">Paper (French)</a>
          <a class="ghost" href="gretsi_english_version.pdf" target="_blank">Paper (English)</a>
          <a class="ghost" href="gretsi_slides.pptx" target="_blank">Slides</a>
        </div>
      </div>
    </article>

    <h3 class="section-subhead">Collaborations</h3>

    <article class="pub-row">
      <div class="pub-rail"><span class="chip chip-primary">Under Review • 2025</span></div>
      <div class="pub-illustration" style="display: flex; align-items: center;">
        <video src="lucy_animation.mov" autoplay loop muted playsinline style="width: 100%; height: auto; border-radius: 12px; border: 1px solid var(--line); display: block; margin: 0 auto;"></video>
      </div>
      <div class="pub-body">
        <h3>From Thought to Action: Hierarchy of Neural Dynamics for Language Production</h3>
        <p class="authors">M. Zhang, J. Lévy, S. d’Ascoli, J. Rapin, F. Alario, P. Bourdillon, S. Pinet, J.-R. King</p>
        <p class="summary">
          We used magnetoencephalography (MEG) and electroencephalography (EEG) to record the brain activity of 35 skilled typists as they composed sentences. This unique approach reveals how the brain organizes language production across multiple levels—from context to words, syllables, and letters. Each level of representation emerges and overlaps in time, forming a dynamic hierarchy of neural codes that orchestrates the transformation of thought into language.
        </p>
        <div class="links">
            <a class="ghost" href="https://arxiv.org/abs/2502.07429" target="_blank">Paper (PDF)</a>
        </div>
      </div>
    </article>

    <article class="pub-row">
      <div class="pub-rail"><span class="chip">Brain • 2022</span></div>
      <div class="pub-illustration" style="display: flex; align-items: center;">
        <img src="sepsis_main_figure.png" alt="Amygdala circuits illustration" style="max-height: 250px; width: auto; display: block; margin: 0 auto;">
      </div>
      <div class="pub-body">
        <h3>Silencing of amygdala circuits during sepsis prevents anxiety-related behaviours</h3>
        <p class="authors">L. Bourhy, A. Mazeraud, L. H. A. Costa, J. Lévy, D. Rei, E. Hecquet, et al.</p>
        <p class="summary">
          Sepsis can trigger lasting psychiatric effects such as anxiety and PTSD, but the brain mechanisms remain unclear. In mice, sepsis caused overactivation of a specific fear circuit linking the amygdala to the bed nucleus of the stria terminalis. This rewiring persisted after recovery and led to anxiety-like behaviors. Temporarily silencing this circuit during the acute phase of sepsis or treating with levetiracetam prevented these effects. Targeting fear circuits early may block post-sepsis psychiatric disorders.
        </p>
        <div class="links">
            <a class="ghost" href="https://pmc.ncbi.nlm.nih.gov/articles/PMC9128826/" target="_blank">Paper (PDF)</a>
        </div>
      </div>
    </article>

    <article class="pub-row">
      <div class="pub-rail"><span class="chip">JCO CCI • 2024</span></div>
      <div class="pub-illustration" style="display: flex; align-items: center;">
        <img src="oncology_illu.png" alt="Oncology illustration" style="max-height: 250px; width: auto; display: block; margin: 0 auto;">
      </div>
      <div class="pub-body">
        <h3>Patients facing large language models in oncology: A narrative review</h3>
        <p class="authors">C. Raynaud, D. Wu, J. Lévy, M. Marengo, J.-E. Bibault</p>
        <p class="summary">
          The integration of large language models (LLMs) into oncology is transforming patients' journeys through education, diagnosis, treatment monitoring, and follow-up. This review examines the current landscape, potential benefits, and associated ethical and regulatory considerations of the application of LLMs for patients in the oncologic domain.
        </p>
        <div class="links">
            <a class="ghost" href="https://ascopubs.org/doi/10.1200/CCI-24-00149" target="_blank">Paper (PDF)</a>
        </div>
      </div>
    </article>

    <article class="pub-row">
      <div class="pub-rail"><span class="chip chip-primary">Under Review • 2025</span></div>
      <div class="pub-illustration" style="display: flex; align-items: center;">
        <img src="SLM_LLM_radiology.png" alt="SLM LLM illustration" style="max-height: 250px; display: block; margin: 0 auto;">
      </div>
      <div class="pub-body">
        <h3>Benchmarking LLMs and SLMs for patient reported outcomes </h3>
        <p class="authors">M. Marengo, J. Lévy, J.-E. Bibault</p>
        <p class="summary">
          Large language models (LLMs) like GPT-4 can already turn patient-reported outcomes into clear medical summaries, helping clinicians focus on what matters most. But privacy remains a major hurdle. This study compares compact small language models (SLMs) to LLMs for summarizing patient Q&A forms in radiotherapy. The results show that while SLMs still trail in accuracy, they offer a compelling path toward secure, efficient, and privacy-preserving AI in healthcare.
        </p>
        <div class="links">
            <a class="ghost" href="https://arxiv.org/abs/2412.16291" target="_blank">Paper (PDF)</a>
        </div>
      </div>
    </article>

    <h3 class="section-subhead">Other Works</h3>

    <div class="other-works-list" style="display:grid; grid-template-columns:repeat(auto-fit,minmax(280px,1fr)); gap:16px; max-width:1200px; margin:16px auto;">
      <article class="other-work" style="border:1px solid var(--line); border-radius:12px; padding:16px; background:var(--card); box-shadow:var(--shadow);">
        <h4 style="margin:0 0 6px; font-size:1rem;">
          <a href="robust_fetus_segmentation.pdf" target="_blank" rel="noopener" style="color:var(--fg); text-decoration:none;">
            Towards robust fetus segmentation from MRI imaging: Accelerating annotations and diving into high semantic features
          </a>
        </h4>
        <p class="mono small subtle" style="margin:0 0 10px;">Jarod Lévy, Charlotte Godard, Jean-Baptiste Masson</p>
        <p style="margin:0;">
          We designed a pipeline to make the creation and analysis of medical databases more efficient, using a tablet app to ease data annotation and a self-supervised inpainting model to extract meaningful features. Applied to the LUMIERE pregnancy MRI dataset, this work contributes to fetal development research and could be extended to other medical imaging projects.
        </p>
      </article>
    </div>

    <div class="other-works-list" style="display:grid; grid-template-columns:repeat(auto-fit,minmax(280px,1fr)); gap:16px; max-width:1200px; margin:16px auto;">
      <article class="other-work" style="border:1px solid var(--line); border-radius:12px; padding:16px; background:var(--card); box-shadow:var(--shadow);">
        <h4 style="margin:0 0 6px; font-size:1rem;">
          <a href="from_trees_to_continuous_embeddings.pdf" target="_blank" rel="noopener" style="color:var(--fg); text-decoration:none;">
            From Trees to Continuous Embeddings and Back: Hyperbolic Hierarchical Clustering — A Comprehensive Report
          </a>
        </h4>
        <p class="mono small subtle" style="margin:0 0 10px;">Jarod Lévy, Paul Meddeb</p>
        <p style="margin:0;">
          Extended analysis of hyperbolic hierarchical clustering across text and synthetic datasets introducing dendrogram purity. Discusses computational limits of the triplet strategy and proposes an alternative sampling approach.
        </p>
      </article>
    </div>

    <section id="weekly" class="reveal">
      <div class="section-head">
        <h2>Writing</h2>
      </div>
    
      <p class="subtle mono">
        During the first 20 weeks, I wrote short articles about what makes me think, smile, or question things during my PhD journey.
        You can click on them to read!
        <br><br>
        I also have a Substack account:
        <a href="https://substack.com/@jarodlevy" target="_blank" rel="noopener noreferrer" style="color:var(--accent);">
          substack.com/@jarodlevy
        </a>
      </p>
    
      <div class="writing-mosaic" id="writing-mosaic"></div>
    
      <!-- Modal -->
      <div id="article-modal" class="article-modal">
        <div class="modal-content">
          <button class="close-modal">&times;</button>
          <h3 id="modal-title">Placeholder Title</h3>
          <p id="modal-text">Placeholder article content</p>
        </div>
      </div>
    
      <script>
        document.addEventListener("DOMContentLoaded", () => {
          const container = document.getElementById("writing-mosaic");
    
          // === DEFINE YOUR 20 ARTICLES HERE ===
          const articles = [
            {   title: "La nuance ne fragilise pas le propos",
                    img: "articles_images/article1.png",
                    text: `
                    <p>En 1945, dans <em>The Crack-Up</em>, F. Scott Fitzgerald écrit : 
                    « La marque d’une intelligence de premier ordre est la capacité de tenir simultanément deux idées opposées dans son esprit tout en conservant la capacité de fonctionner. »</p>

                    <p>Être doctorant confère un statut un peu particulier : sans être reconnu comme un expert, nous sommes pourtant en première ligne. 
                    Le métier de chercheur a cela d’original que l’on passe une majorité de notre temps à explorer des hypothèses fausses. 
                    Pourtant il est de plus en plus dur de dire ouvertement “je ne sais pas”. On craint de ne plus être pris au sérieux. 
                    Cela impacte l'ensemble du monde de la recherche. Trop de publications positives, pas assez de publications négatives. 
                    Rester discipliné dans ses recherches, ne pas céder à la tentation d’enjoliver ses résultats et concéder parfois que l’on ne sait simplement pas est fondamental, 
                    comme l’explique le journaliste Alexandre Morales dans son émission du 25 décembre sur France Culture [1]. 
                    C’est le premier rempart à la désinformation. Car si la recherche triche, qui ne trichera pas ?</p>

                    <p>À l'extérieur du monde de la recherche, la société semble avoir changé de configuration. 
                    On encourage maintenant la prise de position tranchée, le cru, l'extrême. 
                    Le public est-il encore à la recherche de la vérité ? 
                    On sait déjà qu’il est beaucoup plus facile de répandre une fausse information qu’une vraie, 
                    comme l’a démontré cet excellent article du MIT Media Lab [2].</p>

                    <p>D’un point de vue cérébral, comment le cerveau appréhende-t-il le fait que la quantité d’information qui nous parvient a brutalement changé d’ordre de grandeur ? 
                    Je me questionne. Combien de temps me suis-je accordé pour avoir un avis sur le nouveau gouvernement syrien ? 
                    Et sur le nouveau Premier ministre français ? Pourquoi devrions-nous avoir un avis sur tout ? 
                    Il semble parfois qu'être informé sans pour autant tout connaître soit devenu impensable. 
                    Et changer de point de vue ? N’en parlons même pas !</p>

                    <p>Je reprends ici largement les propos d'Étienne Klein, Ismaël Khelifa et d'autres qui prônent une nuance immodérée.</p>

                    <p>Cela semble évident, c’est vrai. Selon la loi de Brandolini [3], 
                    "la quantité d'énergie nécessaire pour réfuter des sottises [...] est supérieure d'un ordre de grandeur à celle nécessaire pour les produire."</p>

                    <p>C'est fatigant, c'est vrai, mais ne laissons pas l'entièreté de la sphère publique aux positionnements schématiques.</p>

                    <p class="subtle small">
                    [1] Alexandre Morales – France Culture (2024).<br>
                    [2] Vosoughi, S., Roy, D., & Aral, S. (2018). The spread of true and false news online. <em>Science</em>, 359(6380), 1146–1151.<br>
                    [3] Bullshit Asymmetry Principle – Alberto Brandolini (2013).
                    
                    
                    <p>        </p>
                    
                    
                    </p>   `
              },
            { title: "Week 2 — The first experiments", img: "articles_images/article2.png", text: "Setting up the pipeline was harder than expected, but I’m learning tons about data quality and preprocessing." },
            { title: "Week 3 — Impostor syndrome", img: "articles_images/article3.png", text: "Everyone seems to know more than me. But maybe that’s what growth feels like." },
            { title: "Week 4 — Small victories", img: "articles_images/article4.png", text: "Finally fixed that bug after three days. I’ve never appreciated a green checkmark so much." },
            { title: "Week 5 — Thinking in systems", img: "articles_images/article5.png", text: "Understanding neural architectures feels like understanding brains — both are complex, elegant, and stubborn." },
            { title: "Week 6 — Collaboration magic", img: "articles_images/article6.png", text: "Discussing with others always unlocks new ideas. Science is definitely a team sport." },
            { title: "Week 7 — Silence of the brain", img: "articles_images/article7.png", text: "Studying silence in EEG signals reminds me how much information hides in what’s *not* said." },
            { title: "Week 8 — The art of debugging", img: "articles_images/article8.png", text: "Debugging feels like therapy — sometimes painful, but you always end up understanding yourself better." },
            { title: "Week 9 — Learning from failure", img: "articles_images/article9.png", text: "A failed experiment isn’t a setback; it’s the system teaching me where to look next." },
            { title: "Week 10 — The midpoint", img: "articles_images/article10.png", text: "Ten weeks in, I realize progress isn’t linear — and that’s okay." },
            { title: "Week 11 — Writing matters", img: "articles_images/article11.png", text: "Putting ideas into words makes them real. Writing is part of the research process, not just the outcome." },
            { title: "Week 12 — On focus", img: "articles_images/article12.png", text: "Learning to protect time and energy is harder than any technical challenge." },
            { title: "Week 13 — The model that spoke", img: "articles_images/article13.png", text: "When your model finally outputs something meaningful, it’s like hearing it speak for the first time." },
            { title: "Week 14 — Mentorship", img: "articles_images/article14.png", text: "Having mentors who listen more than they talk — that’s rare, and precious." },
            { title: "Week 15 — Between intuition and rigor", img: "articles_images/article15.png", text: "Balancing creativity and discipline is what makes science an art." },
            { title: "Week 16 — Cognitive fatigue", img: "articles_images/article16.png", text: "Brains, models, and researchers all need rest to work well." },
            { title: "Week 17 — Presentation day", img: "articles_images/article17.png", text: "Standing in front of peers, explaining your work — terrifying and exhilarating at the same time." },
            { title: "Week 18 — Data empathy", img: "articles_images/article18.png", text: "Behind every dataset are people, contexts, and imperfections worth understanding." },
            { title: "Week 19 — The unexpected insight", img: "articles_images/article19.png", text: "Breakthroughs often come when you stop trying to force them." },
            { title: "Week 20 — Reflection", img: "articles_images/article20.png", text: "Twenty weeks later, I see how curiosity and patience quietly compound." }
          ];
    
          // === RENDER VIGNETTES ===
          articles.forEach((a, i) => {
            const div = document.createElement("div");
            div.className = "writing-card";
            div.dataset.article = i;
            div.style.setProperty("--r", `${(Math.random() - 0.5) * 8}deg`);
            div.style.setProperty("--x", `${(Math.random() - 0.5) * 20}px`);
            div.style.setProperty("--y", `${(Math.random() - 0.5) * 20}px`);
            div.innerHTML = `
              <div class="card-inner">
                <img src="${a.img}" alt="${a.title}">
                <div class="card-label"><h5>${a.title}</h5></div>
              </div>
            `;
            container.appendChild(div);
          });
    
          // === MODAL LOGIC ===
          const modal = document.getElementById("article-modal");
          const closeBtn = modal.querySelector(".close-modal");
          const modalTitle = document.getElementById("modal-title");
          const modalText = document.getElementById("modal-text");
    
          container.addEventListener("click", (e) => {
            const card = e.target.closest(".writing-card");
            if (!card) return;
            const a = articles[+card.dataset.article];
            modalTitle.textContent = a.title;
            modalText.innerHTML = a.text;
            modal.classList.add("active");
            document.body.style.overflow = "hidden";
          });
    
          const closeModal = () => {
            modal.classList.remove("active");
            document.body.style.overflow = "";
          };
          closeBtn.addEventListener("click", closeModal);
          modal.addEventListener("click", (e) => { if (e.target === modal) closeModal(); });
        });
      </script>
    </section>

  <!-- OUTSIDE WORK -->
  <section id="outside-work" class="reveal">
    <div class="section-head"><h2>Outside Work</h2></div>
    <p class="subtle mono">This section is under construction. Stay tuned for updates!</p>
  </section>

  <!-- CV -->
  <section id="cv" class="reveal">
    <div class="cv-box">
      <h2>Curriculum Vitae</h2>
      <a class="cta" href="CV.pdf" target="_blank">View CV (PDF)</a>
    </div>
  </section>

  <footer class="intro-footer">
    <div class="intro-foot-left">
      <p><strong>Jarod Lévy</strong><br>PhD Student, Meta FAIR × Inria</p>
    </div>
    <div class="intro-foot-center">
      <p>© <span id="year"></span> Jarod Lévy. All rights reserved.</p>
    </div>
    <div class="intro-foot-right">
      <div class="socials footer-socials" aria-label="Social links">
        <a href="https://scholar.google.com/citations?user=jx5DNj0AAAAJ&hl=fr&oi=sra" title="Google Scholar" aria-label="Google Scholar">
          <iconify-icon icon="simple-icons:googlescholar"></iconify-icon>
        </a>
        <a href="https://github.com/jarod1212" title="GitHub" aria-label="GitHub">
          <iconify-icon icon="mdi:github"></iconify-icon>
        </a>
        <a href="https://x.com/JarodLevy" title="X (Twitter)" aria-label="X (Twitter)">
          <iconify-icon icon="simple-icons:x"></iconify-icon>
        </a>
        <a href="https://www.linkedin.com/in/jarod-l%C3%A9vy-645b4214b/" title="LinkedIn" aria-label="LinkedIn">
          <iconify-icon icon="mdi:linkedin"></iconify-icon>
        </a>
      </div>
    </div>
  </footer>

  <script defer src="phd-timer.js"></script>

  <script>
    document.addEventListener("DOMContentLoaded", () => {
      const container = document.getElementById("writing-mosaic");
    
      // Create each vignette with random offset and rotation
      articles.forEach((a) => {
        const div = document.createElement("div");
        div.className = "writing-card funky";
        div.dataset.article = a.id;
        div.style.setProperty("--r", `${(Math.random() - 0.5) * 8}deg`);
        div.style.setProperty("--x", `${(Math.random() - 0.5) * 20}px`);
        div.style.setProperty("--y", `${(Math.random() - 0.5) * 20}px`);
        div.innerHTML = `
          <div class="card-inner">
            <img src="${a.img}" alt="Article ${a.id}">
            <div class="card-label"><h5>${a.title}</h5></div>
          </div>
        `;
        container.appendChild(div);
      });
    
      const modal = document.getElementById("article-modal");
      const closeBtn = modal.querySelector(".close-modal");
      const modalTitle = document.getElementById("modal-title");
      const modalText = document.getElementById("modal-text");
    
      container.addEventListener("click", (e) => {
        const card = e.target.closest(".writing-card");
        if (!card) return;
        const id = +card.dataset.article;
        const a = articles[id - 1];
        modalTitle.textContent = a.title;
        modalText.textContent = a.text;
        modal.classList.add("active");
        document.body.style.overflow = "hidden";
      });
    
      const closeModal = () => {
        modal.classList.remove("active");
        document.body.style.overflow = "";
      };
      closeBtn.addEventListener("click", closeModal);
      modal.addEventListener("click", (e) => {
        if (e.target === modal) closeModal();
      });
    });
    </script>


</body>
</html>
